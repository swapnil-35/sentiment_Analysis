# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCKNgpJWh8heGwg6k1bKrNlh1m8NlI48

# **Install and Import Deoendencies**
"""

!pip install transformers datasets evaluate accelerate
from transformers import pipeline,AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,Trainer
from datasets import load_dataset
import numpy as np
import evaluate

"""# **Demo Pipeline(before training)**"""

demo_pipe = pipeline(task = "sentiment-analysis")

text = 'This movie was fantastic!'

result = demo_pipe(text)

print(result)

demo_pipeline = pipeline(task = 'sentiment-analysis')

text = 'The film was terrible and boring'

result = demo_pipeline(text)

print(result)

"""# **Load IMDB Dataset(Binary_Sentiment)**"""

dataset = load_dataset('imdb')
print(dataset)

print(dataset['train']) # show meta data

print(dataset['train'][10]) # show actual data 10th row

print(dataset['train'].features) # show features

dataset['train'][:10]

print(dataset['test'][2])

"""# *Tokenization*"""

model = 'distilbert-base-uncased'
tokenizer = AutoTokenizer.from_pretrained(model)

def tokenize_function(example):
  return tokenizer(example['text'],truncation = True,padding = 'max_length',max_length = 256)

tokenized = dataset.map(tokenize_function,batched = True)
small_train = tokenized['train'].shuffle(seed = 42).select(range(2000))
small_test = tokenized['test'].shuffle(seed = 42).select(range(1000))

"""# **Fine Tunning Using Hugging Face Trainer**"""

model_name = 'distilbert-base-uncased'
model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels = 2)


args = TrainingArguments(
    output_dir = './binary_cls_results',
    eval_strategy = 'epoch',
    learning_rate = 2e-5,
    per_device_train_batch_size = 16,
    per_device_eval_batch_size = 16,
    num_train_epochs =2,
    weight_decay = 0.01,
    logging_dir = './binary_cls_logs'
)

accuracy = evaluate.load('accuracy')
precision = evaluate.load('precision')
recall = evaluate.load('recall')
f1 = evaluate.load('f1')

def compute_metrics(eval_pred):
  logits,labels = eval_pred
  preds = np.argmax(logits,axis=-1)

  return {
      'accuracy':accuracy.compute(predictions = preds,references = labels)['accuracy'],
      'precision':precision.compute(predictions = preds,references = labels, average="binary")['precision'],
      'recall':recall.compute(predictions = preds,references = labels, average="binary")['recall'],
      'f1':f1.compute(predictions = preds,references = labels, average="binary")['f1']
  }

trainer = Trainer(
    model = model,
    args = args,
    train_dataset = small_train,
    eval_dataset = small_test,
    tokenizer = tokenizer,
    compute_metrics = compute_metrics
)

trainer.train()

"""# **Evaluate Model**"""

result = trainer.evaluate()
print(result)

"""# **Save Model Locally**"""

save_dir = './binary_text_classification_model'
trainer.save_model(save_dir)
tokenizer.save_pretrained(save_dir)
print('Saved model to',save_dir)

"""# **Load the Saved Model & Tokenizer**"""

tokenizer = AutoTokenizer.from_pretrained(save_dir)
model = AutoModelForSequenceClassification.from_pretrained(save_dir)

"""# **Predictions**"""

classifier = pipeline(
    task = 'sentiment-analysis',
    model = model,
    tokenizer = tokenizer
)

text = "I really loved this movie! It was fantastic."

result = classifier(text)
print(result)

# predicting multiple reviews

reviews = [
    "The movie was absolutely amazing!",
    "I hated the acting and the story was boring.",
    "It was okay, but not the best."
]

result = classifier(reviews)
print(result)

"""# **Push to Hugging Face Hub**"""

from huggingface_hub import notebook_login
notebook_login()

trainer.push_to_hub('binary_text_classification_model_swapnil12')

"""# **Using from Huggingface hub**"""

sentiment_pipeline = pipeline(
    task = 'sentiment-analysis',
    model = "swapnil-12/binary_cls_results"
)

text = ' I love eating traditional and healthy food'

result = sentiment_pipeline(text)
print(result)